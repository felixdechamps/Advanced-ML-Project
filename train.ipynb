{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53f38491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63593afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 10:46:11.547923: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-03 10:46:11.548419: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-03 10:46:11.615687: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-03 10:46:13.399890: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-03 10:46:13.400356: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/opt/python/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c7146c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 100\n",
    "\n",
    "def make_save_dir(dirname, experiment_name):\n",
    "    start_time = str(int(time.time())) + '-' + str(random.randrange(1000))\n",
    "    save_dir = os.path.join(dirname, experiment_name, start_time)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    return save_dir\n",
    "\n",
    "def get_filename_for_saving(save_dir):\n",
    "    return os.path.join(save_dir,\n",
    "            \"{val_loss:.3f}-{val_acc:.3f}-{epoch:03d}-{loss:.3f}-{acc:.3f}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ba6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"conv_subsample_lengths\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    \"conv_filter_length\": 16,\n",
    "    \"conv_num_filters_start\": 32,\n",
    "    \"conv_init\": \"he_normal\",\n",
    "    \"conv_activation\": \"relu\",\n",
    "    \"conv_dropout\": 0.2,\n",
    "    \"conv_num_skip\": 2,\n",
    "    \"conv_increase_channels_at\": 4,\n",
    "\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "\n",
    "    \"train\": \"train.json\",\n",
    "    \"dev\": \"dev.json\",\n",
    "\n",
    "    \"generator\": True,\n",
    "\n",
    "    \"save_dir\": \"saved\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439e79c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7676/7676 [00:01<00:00, 4216.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X) : \n",
      " 7676\n",
      "len(y) : \n",
      " 7676\n",
      "ecg_0 : \n",
      " [  72   83   93 ... -136 -133 -131]\n",
      "len(ecg_0) : 8960\n",
      "label_0 :\n",
      " ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "len(label_0) : 35\n",
      "ecg_1 : \n",
      " [-137 -167 -200 ...  -50  -51  -51]\n",
      "len(ecg_1) : 8960\n",
      "label_1 :\n",
      " ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "len(label_1) : 35\n",
      "ecg_2 : \n",
      " [620 780 914 ... 102 115 116]\n",
      "len(ecg_2) : 8960\n",
      "label_2 :\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "len(label_2) : 35\n",
      "ecg_3 : \n",
      " [ 96 116 128 ...  45  52  62]\n",
      "len(ecg_3) : 8960\n",
      "label_3 :\n",
      " ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "len(label_3) : 35\n",
      "ecg_4 : \n",
      " [702 837 986 ... 150 147 143]\n",
      "len(ecg_4) : 8960\n",
      "label_4 :\n",
      " ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "len(label_4) : 35\n",
      "ecg_5 : \n",
      " [ -986 -1188 -1396 ...   266   390   531]\n",
      "len(ecg_5) : 8960\n",
      "label_5 :\n",
      " ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "len(label_5) : 35\n",
      "ecg_6 : \n",
      " [ 19  17  12 ... 274 269 260]\n",
      "len(ecg_6) : 6656\n",
      "label_6 :\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "len(label_6) : 26\n",
      "ecg_7 : \n",
      " [132 163 198 ... -46 -43 -40]\n",
      "len(ecg_7) : 8960\n",
      "label_7 :\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "len(label_7) : 35\n",
      "ecg_8 : \n",
      " [-10 -12 -13 ... -61 -62 -62]\n",
      "len(ecg_8) : 8960\n",
      "label_8 :\n",
      " ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "len(label_8) : 35\n",
      "ecg_9 : \n",
      " [153 182 216 ...  89  88  88]\n",
      "len(ecg_9) : 17920\n",
      "label_9 :\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "len(label_9) : 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training set...\")\n",
    "train = load.load_dataset(params['train'])\n",
    "ecgs, labels = train\n",
    "print(f\"len(X) : \\n {len(ecgs)}\")\n",
    "print(f\"len(y) : \\n {len(labels)}\")\n",
    "for i in range(10):\n",
    "    print(f\"ecg_{i} : \\n {ecgs[i]}\")\n",
    "    print(f\"len(ecg_{i}) : {len(ecgs[i])}\")\n",
    "    print(f\"label_{i} :\\n {labels[i]}\")\n",
    "    print(f\"len(label_{i}) : {len(labels[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "489b6ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dev set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:00<00:00, 4903.11it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dev set...\")\n",
    "dev = load.load_dataset(params['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11a928d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building preprocessor...\n",
      "self.mean :  7.4661856  self.std :  236.10312\n",
      "self.classes :  ['A', 'N', 'O', '~']\n",
      "self.int_to_class :  {0: 'A', 1: 'N', 2: 'O', 3: '~'}\n",
      "self.class_to_int :  {'A': 0, 'N': 1, 'O': 2, '~': 3}\n",
      "Training size: 7676 examples.\n",
      "Dev size: 852 examples.\n"
     ]
    }
   ],
   "source": [
    "print(\"Building preprocessor...\")\n",
    "preproc = load.Preproc(*train)\n",
    "print(\"Training size: \" + str(len(train[0])) + \" examples.\")\n",
    "print(\"Dev size: \" + str(len(dev[0])) + \" examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2762b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet1d import MyDataset, ResNet1D\n",
    "\n",
    "train_dataset = MyDataset(*train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80f5e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,labels = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dc40354",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data[:5], labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1048e718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  72,   83,   93, ..., -136, -133, -131],\n",
       "       shape=(8960,), dtype=int16),\n",
       " array([-137, -167, -200, ...,  -50,  -51,  -51],\n",
       "       shape=(8960,), dtype=int16),\n",
       " array([620, 780, 914, ..., 102, 115, 116], shape=(8960,), dtype=int16),\n",
       " array([ 96, 116, 128, ...,  45,  52,  62], shape=(8960,), dtype=int16),\n",
       " array([702, 837, 986, ..., 150, 147, 143], shape=(8960,), dtype=int16)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0959c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa3aa631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "for el in y : \n",
    "    print(len(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79d88c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.27332893],\n",
       "        [ 0.31991875],\n",
       "        [ 0.36227313],\n",
       "        ...,\n",
       "        [-0.60764205],\n",
       "        [-0.5949358 ],\n",
       "        [-0.5864649 ]],\n",
       "\n",
       "       [[-0.6118775 ],\n",
       "        [-0.7389406 ],\n",
       "        [-0.8787101 ],\n",
       "        ...,\n",
       "        [-0.24339443],\n",
       "        [-0.24762988],\n",
       "        [-0.24762988]],\n",
       "\n",
       "       [[ 2.5943487 ],\n",
       "        [ 3.2720187 ],\n",
       "        [ 3.8395672 ],\n",
       "        ...,\n",
       "        [ 0.40039206],\n",
       "        [ 0.45545274],\n",
       "        [ 0.4596882 ]],\n",
       "\n",
       "       [[ 0.37497944],\n",
       "        [ 0.4596882 ],\n",
       "        [ 0.5105134 ],\n",
       "        ...,\n",
       "        [ 0.15897211],\n",
       "        [ 0.18862018],\n",
       "        [ 0.23097456]],\n",
       "\n",
       "       [[ 2.9416544 ],\n",
       "        [ 3.5134387 ],\n",
       "        [ 4.144519  ],\n",
       "        ...,\n",
       "        [ 0.60369307],\n",
       "        [ 0.5909867 ],\n",
       "        [ 0.574045  ]]], shape=(5, 8960, 1), dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.process_x(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "638c2664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN :  7.4661856  STD :  236.10312\n",
      "self.classes :  ['A', 'N', 'O', '~']\n",
      "self.class_to_int :  {'A': 0, 'N': 1, 'O': 2, '~': 3}\n"
     ]
    }
   ],
   "source": [
    "from load_data import ECGDataset, ECGCollate, SmartBatchSampler\n",
    "\n",
    "train_dataset = ECGDataset(*train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eda3a482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tri du dataset par longueur pour minimiser le padding...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instanciation du Sampler intelligent\n",
    "batch_sampler = SmartBatchSampler(dataset, 32)\n",
    "\n",
    "collate_fn = ECGCollate(\n",
    "    pad_val_x=dataset.pad_value_x_normalized,\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    # IMPORTANT : Quand on utilise batch_sampler, on ne met ni batch_size, ni shuffle, ni drop_last\n",
    "    # dans le DataLoader car le Sampler gère tout ça.\n",
    "    batch_sampler=batch_sampler, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0da33b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.5943, 3.2720, 3.8396,  ..., 0.4004, 0.4555, 0.4597]),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6e806a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17920/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2bfc355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 5632]) torch.Size([32, 22])\n",
      "torch.Size([32, 1, 4864]) torch.Size([32, 19])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 9472]) torch.Size([32, 37])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 7936]) torch.Size([32, 31])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 9728]) torch.Size([32, 38])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 4864]) torch.Size([32, 19])\n",
      "torch.Size([32, 1, 3072]) torch.Size([32, 12])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 3840]) torch.Size([32, 15])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 10496]) torch.Size([32, 41])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 9728]) torch.Size([32, 38])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 15104]) torch.Size([32, 59])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 9216]) torch.Size([32, 36])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 3584]) torch.Size([32, 14])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 3072]) torch.Size([32, 12])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 11776]) torch.Size([32, 46])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 5120]) torch.Size([32, 20])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 5376]) torch.Size([32, 21])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 14080]) torch.Size([32, 55])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 12288]) torch.Size([32, 48])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17664]) torch.Size([32, 69])\n",
      "torch.Size([32, 1, 3584]) torch.Size([32, 14])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 16384]) torch.Size([32, 64])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 9984]) torch.Size([32, 39])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 6656]) torch.Size([32, 26])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 4608]) torch.Size([32, 18])\n",
      "torch.Size([32, 1, 5888]) torch.Size([32, 23])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 7680]) torch.Size([32, 30])\n",
      "torch.Size([32, 1, 7424]) torch.Size([32, 29])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 9472]) torch.Size([32, 37])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 2816]) torch.Size([32, 11])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 13568]) torch.Size([32, 53])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 4352]) torch.Size([32, 17])\n",
      "torch.Size([32, 1, 7168]) torch.Size([32, 28])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 3328]) torch.Size([32, 13])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 11008]) torch.Size([32, 43])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 10752]) torch.Size([32, 42])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 4096]) torch.Size([32, 16])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17152]) torch.Size([32, 67])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 6144]) torch.Size([32, 24])\n",
      "torch.Size([32, 1, 6912]) torch.Size([32, 27])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 6144]) torch.Size([32, 24])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 10240]) torch.Size([32, 40])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 11264]) torch.Size([32, 44])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 3840]) torch.Size([32, 15])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8192]) torch.Size([32, 32])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([28, 1, 18176]) torch.Size([28, 71])\n",
      "torch.Size([32, 1, 17920]) torch.Size([32, 70])\n",
      "torch.Size([32, 1, 12800]) torch.Size([32, 50])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8704]) torch.Size([32, 34])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n",
      "torch.Size([32, 1, 8960]) torch.Size([32, 35])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader : \n",
    "    x,y = batch\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "694e248c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6926,  0.8875,  1.1119,  ..., -0.4975, -0.4890, -0.4806]],\n",
       "\n",
       "        [[ 0.0658,  0.0954,  0.1251,  ..., -0.2942, -0.2773, -0.2646]],\n",
       "\n",
       "        [[ 0.1505,  0.1886,  0.2225,  ...,  2.4927,  2.5096,  2.5223]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9383,  1.2263,  1.5143,  ..., -0.4298, -0.4086, -0.3874]],\n",
       "\n",
       "        [[ 0.1039,  0.2183,  0.2522,  ..., -0.0316, -0.0316, -0.0316]],\n",
       "\n",
       "        [[-2.9244, -3.6063, -4.3433,  ...,  0.1463,  0.1420,  0.1378]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1480a8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [2, 2, 2,  ..., 2, 2, 2],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940bc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse  # Module pour gérer les arguments passés en ligne de commande\n",
    "\n",
    "# Création du parseur d'arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Argument positionnel obligatoire : chemin vers un fichier de configuration\n",
    "parser.add_argument(\n",
    "    \"config_file\",\n",
    "    help=\"path to config file\"\n",
    ")\n",
    "\n",
    "# Argument optionnel : nom de l'expérience\n",
    "# Peut être fourni avec --experiment ou -e\n",
    "# Valeur par défaut : \"default\"\n",
    "parser.add_argument(\n",
    "    \"--experiment\",\n",
    "    \"-e\",\n",
    "    help=\"tag with experiment name\",\n",
    "    default=\"default\"\n",
    ")\n",
    "\n",
    "# Analyse des arguments fournis lors de l'exécution du script\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Après cette ligne :\n",
    "# args.config_file contient le chemin du fichier de configuration\n",
    "# args.experiment contient le nom de l'expérience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "173a428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_subsample_lengths': [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], 'conv_filter_length': 16, 'conv_num_filters_start': 32, 'conv_init': 'he_normal', 'conv_activation': 'relu', 'conv_dropout': 0.2, 'conv_num_skip': 2, 'conv_increase_channels_at': 4, 'learning_rate': 0.001, 'batch_size': 32, 'train': 'train.json', 'dev': 'dev.json', 'generator': True, 'save_dir': 'saved', 'input_shape': [None, 1], 'num_categories': 4}\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "save_dir = make_save_dir(params['save_dir'], \"test_run\")\n",
    "\n",
    "util.save(preproc, save_dir)\n",
    "\n",
    "params.update({\n",
    "    \"input_shape\": [None, 1],\n",
    "    \"num_categories\": len(preproc.classes)\n",
    "})\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1759e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7548ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable),total=len(iterable), ncols=150, desc=desc)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss_func, tb_logger, epochs=10, name=\"default\"):\n",
    "    \"\"\"\n",
    "    Train the classifier for a number of epochs.\n",
    "    \"\"\"\n",
    "    loss_cutoff = len(train_loader) // 10\n",
    "    optimizer = torch.optim.Adam(model.parameters(), params[\"learning_rate\"])\n",
    "\n",
    "    # The scheduler is used to change the learning rate every few \"n\" steps.\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * len(train_loader) / 5), gamma=hparams.get('gamma', 0.8))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Training stage, where we want to update the parameters.\n",
    "        model.train()  # Set the model to training mode\n",
    "\n",
    "        training_loss = []\n",
    "        validation_loss = []\n",
    "\n",
    "        # Create a progress bar for the training loop.\n",
    "        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]')\n",
    "        for train_iteration, batch in training_loop:\n",
    "            optimizer.zero_grad() # Reset the gradients - VERY important! Otherwise they accumulate.\n",
    "            images, labels = batch # Get the images and labels from the batch, in the fashion we defined in the dataset and dataloader.\n",
    "            images, labels = images.to(device), labels.to(device) # Send the data to the device (GPU or CPU) - it has to be the same device as the model.\n",
    "\n",
    "            # Flatten the images to a vector. This is done because the classifier expects a vector as input.\n",
    "            # Could also be done by reshaping the images in the dataset.\n",
    "            images = images.view(images.shape[0], -1)\n",
    "\n",
    "            pred = model(images) # Stage 1: Forward().\n",
    "            loss = loss_func(pred, labels) # Compute the loss over the predictions and the ground truth.\n",
    "            loss.backward()  # Stage 2: Backward().\n",
    "            optimizer.step() # Stage 3: Update the parameters.\n",
    "            scheduler.step() # Update the learning rate.\n",
    "\n",
    "\n",
    "            training_loss.append(loss.item())\n",
    "            training_loss = training_loss[-loss_cutoff:]\n",
    "\n",
    "            # Update the progress bar.\n",
    "            training_loop.set_postfix(curr_train_loss = \"{:.8f}\".format(np.mean(training_loss)),\n",
    "                                      lr = \"{:.8f}\".format(optimizer.param_groups[0]['lr'])\n",
    "            )\n",
    "\n",
    "            # Update the tensorboard logger.\n",
    "            tb_logger.add_scalar(f'classifier_{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n",
    "\n",
    "        # Validation stage, where we don't want to update the parameters. Pay attention to the classifier.eval() line\n",
    "        # and \"with torch.no_grad()\" wrapper.\n",
    "        model.eval()\n",
    "        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                pred = model(images)\n",
    "                loss = loss_func(pred, labels)\n",
    "                validation_loss.append(loss.item())\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(val_loss = \"{:.8f}\".format(np.mean(validation_loss)))\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                tb_logger.add_scalar(f'classifier_{name}/val_loss', loss.item(), epoch * len(val_loader) + val_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb145a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard logger.\n",
    "# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n",
    "# Also, in order to reset the logs, delete the logs folder MANUALLY.\n",
    "\n",
    "path = \"logs\"\n",
    "num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "path = os.path.join(path, f'run_{num_of_runs + 1}')\n",
    "\n",
    "tb_logger = SummaryWriter(path)\n",
    "\n",
    "# Train the classifier.\n",
    "train_loader = data_module.train_dataloader()\n",
    "labled_val_loader = data_module.val_dataloader()\n",
    "\n",
    "epochs = hparams.get('epochs', 4)\n",
    "loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n",
    "# make model\n",
    "device_str = \"cuda\"\n",
    "device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "kernel_size = 16 # 16 in Hannun et al.\n",
    "stride = 2\n",
    "n_block = 16 # 16 in Hannun et al.\n",
    "downsample_gap = 2 # 2 in Hannun et al.\n",
    "increasefilter_gap = 4 # 4 in Hannun et al.\n",
    "\n",
    "model = ResNet1D(\n",
    "    in_channels=1, \n",
    "    base_filters=32, # 32 in Hannun et al.\n",
    "    kernel_size=kernel_size, \n",
    "    stride=stride, \n",
    "    groups=1, # like a classical ResNet\n",
    "    n_block=n_block, \n",
    "    n_classes=2, \n",
    "    downsample_gap=downsample_gap, \n",
    "    increasefilter_gap=increasefilter_gap, \n",
    "    use_bn=True,\n",
    "    use_do=True,\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "summary(model, (X_train.shape[1], X_train.shape[2]), device=device_str)\n",
    "train_model(model, labled_train_loader, labled_val_loader, loss_func, tb_logger, epochs=epochs, name=\"Default\")\n",
    "\n",
    "print()\n",
    "print(\"Finished training!\")\n",
    "print(\"How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\")\n",
    "print(f\"Training Acc: {model.getTestAcc(labled_train_loader)[1] * 100}%\")\n",
    "print(f\"Validation Acc: {model.getTestAcc(labled_val_loader)[1] * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
