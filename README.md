# ECG Classification - Reproduction de Hannun et al. (2019)

Ce projet reproduit les r√©sultats de l'article **"Cardiologist-Level Arrhythmia Detection and Classification in Ambulatory Electrocardiograms Using a Deep Neural Network"** de Hannun et al. (2019) publi√© dans Nature Medicine, en utilisant le dataset PhysioNet/CinC Challenge 2017.

## üìö R√©f√©rences

### Articles principaux
1. **Hannun et al. (2019)** - *Nature Medicine* - "Cardiologist-Level Arrhythmia Detection and Classification"
   - Architecture ResNet 34 couches pour classification ECG
   - Performance cardiologiste sur 12 classes de rythmes
   
2. **Sahu et al. (2022)** - *IEEE EMBC* - "LTH-ECG: Lottery Ticket Hypothesis-based Deep Learning Model Compression"
   - Compression du mod√®le de Hannun et al. par 142x
   - Performance maintenue avec <1% de perte

### Repositories GitHub
- **awni/ecg**: https://github.com/awni/ecg/tree/master (Hannun et al. - TensorFlow)
- **hsd1503/resnet1d**: https://github.com/hsd1503/resnet1d (Impl√©mentation ResNet1D PyTorch)

### Dataset
- **PhysioNet/CinC Challenge 2017**: https://physionet.org/content/challenge-2017/1.0.0/
- 8,528 enregistrements ECG mono-d√©rivation
- 4 classes: Normal, AF (Fibrillation Auriculaire), Other, Noisy

## üèóÔ∏è Architecture du projet

```
ecg_classification/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py              # Chargement dataset PhysioNet 2017
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ resnet1d.py             # Architecture ResNet1D (34 couches)
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py              # M√©triques d'√©valuation (F1, AUC, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ training.py             # Utilitaires d'entra√Ænement
‚îú‚îÄ‚îÄ config.py                   # Configuration (hyperparam√®tres)
‚îú‚îÄ‚îÄ train.py                    # Script d'entra√Ænement principal
‚îú‚îÄ‚îÄ evaluate.py                 # Script d'√©valuation
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## üìã Pr√©requis

### Installation des d√©pendances

```bash
pip install torch torchvision torchaudio
pip install numpy pandas scikit-learn scipy matplotlib seaborn tqdm
```

Ou avec le fichier requirements.txt :

```bash
pip install -r requirements.txt
```

### requirements.txt
```
torch>=2.0.0
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
scipy>=1.10.0
matplotlib>=3.7.0
seaborn>=0.12.0
tqdm>=4.65.0
```

## üì• T√©l√©chargement des donn√©es

### 1. T√©l√©charger le dataset PhysioNet 2017

```bash
# Cr√©er le r√©pertoire des donn√©es
mkdir -p data/physionet2017
cd data/physionet2017

# T√©l√©charger les fichiers
wget -r -N -c -np https://physionet.org/files/challenge-2017/1.0.0/training2017/

# Les donn√©es seront dans training2017/
```

### 2. Structure attendue des donn√©es

```
data/physionet2017/
‚îú‚îÄ‚îÄ REFERENCE.csv              # Labels (format: A00001,N)
‚îú‚îÄ‚îÄ A00001.mat                 # Fichier ECG 1
‚îú‚îÄ‚îÄ A00002.mat                 # Fichier ECG 2
‚îî‚îÄ‚îÄ ...
```

Le fichier `REFERENCE.csv` contient les labels au format :
```
A00001,N
A00002,A
A00003,O
A00004,~
```

O√π :
- N = Normal sinus rhythm
- A = Atrial Fibrillation (AF)
- O = Other rhythms  
- ~ = Noisy

## üöÄ Utilisation

### 1. Entra√Ænement du mod√®le

```bash
python train.py
```

**Param√®tres de training (config.py)** bas√©s sur Hannun et al. :
- Optimiseur : Adam (Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999)
- Learning rate initial : 1e-3
- Batch size : 128
- Dropout : 0.2
- Kernel size : 16
- Base filters : 32

L'entra√Ænement suit la proc√©dure de Hannun et al. :
1. Initialisation He des poids (He et al., 2015)
2. R√©duction du learning rate par 10 si la loss de validation stagne pendant 2 √©poques
3. Sauvegarde du meilleur mod√®le bas√© sur le F1-score de validation
4. Early stopping si pas d'am√©lioration pendant 10 √©poques

### 2. Reprendre un entra√Ænement

```bash
python train.py --resume checkpoints/best_model.pth
```

### 3. √âvaluation du mod√®le

```bash
python evaluate.py --checkpoint checkpoints/best_model.pth --plot --save-results
```

Options :
- `--checkpoint` : Chemin vers le checkpoint du mod√®le (requis)
- `--plot` : G√©n√©rer les visualisations (confusion matrix, ROC curves)
- `--save-results` : Sauvegarder les r√©sultats dans un fichier .npz
- `--output-dir` : R√©pertoire de sortie (d√©faut: ./results)

## üìä M√©triques d'√©valuation

### M√©triques principales (Hannun et al.)

1. **F1-Score** : Moyenne harmonique de la pr√©cision et du recall
   - Calcul√© par classe
   - Moyenne macro (non pond√©r√©e)
   - Moyenne pond√©r√©e (par fr√©quence de classe)

2. **AUC** : Area Under ROC Curve
   - Strat√©gie one-vs-rest
   - Par classe et moyenne

3. **Sensitivity (Recall)** et **Specificity**
   - Par classe
   - Comparaison avec cardiologues

### R√©sultats attendus (Hannun et al. - Supplementary Table 7)

Sur le dataset PhysioNet 2017 :

| Classe | F1-Score |
|--------|----------|
| Normal | 0.909    |
| AF     | 0.827    |
| Other  | 0.772    |
| Noisy  | 0.506    |
| **Moyenne** | **0.836** |

## üîç D√©tails de l'architecture

### ResNet1D (34 couches)

Bas√©e sur Hannun et al. Extended Data Figure 1 :

```
Input: (batch, 1, 9000) - ECG mono-d√©rivation 30s √† 300Hz

Conv1D (kernel=16, stride=2) ‚Üí BatchNorm ‚Üí ReLU

16 Residual Blocks organis√©s en 4 groupes :
‚îú‚îÄ‚îÄ Blocks 1-4:   32 filters  (k=0, 32√ó2‚Å∞)
‚îú‚îÄ‚îÄ Blocks 5-8:   64 filters  (k=1, 32√ó2¬π)
‚îú‚îÄ‚îÄ Blocks 9-12:  128 filters (k=2, 32√ó2¬≤)
‚îî‚îÄ‚îÄ Blocks 13-16: 256 filters (k=3, 32√ó2¬≥)

Chaque Residual Block :
‚îú‚îÄ‚îÄ BatchNorm ‚Üí ReLU ‚Üí Dropout(0.2) ‚Üí Conv1D(kernel=16)
‚îú‚îÄ‚îÄ BatchNorm ‚Üí ReLU ‚Üí Dropout(0.2) ‚Üí Conv1D(kernel=16)
‚îî‚îÄ‚îÄ Shortcut connection (identity ou projection)

Downsampling : stride=2 tous les 2 blocks (blocks altern√©s)

Global Average Pooling ‚Üí Linear(256, 4) ‚Üí Softmax

Output: (batch, 4) - Probabilit√©s des classes
```

**Nombre de param√®tres** : ~10.5M (comme Hannun et al.)

### Justifications architecturales

1. **Pre-activation design** (He et al., 2016)
   ```python
   # Hannun et al. : "Before each convolutional layer we applied 
   # Batch Normalization and a rectified linear activation"
   out = self.bn1(x)
   out = self.relu1(out)
   out = self.conv1(out)
   ```

2. **Shortcut connections** (He et al., 2016)
   ```python
   # Hannun et al. : "employed shortcut connections in manner similar to 
   # Residual Network architecture"
   out = conv_block(x) + shortcut(x)
   ```

3. **Dropout** (Srivastava et al., 2014)
   ```python
   # Hannun et al. : "applied Dropout... with probability of 0.2"
   self.dropout = nn.Dropout(p=0.2)
   ```

4. **Filter progression**
   ```python
   # Hannun et al. : "32*2^k filters, where k starts at zero and 
   # incremented by one every fourth residual block"
   filters = base_filters * (2 ** k)
   ```

## üî¨ Preprocessing des donn√©es

### Signal ECG (dataset.py)

```python
# PhysioNet 2017 : Signaux de longueur variable (9-60s, moyenne ~30s)
# Hannun et al. : Segments de 30s

target_length = 9000  # 30s √ó 300Hz

# Si signal trop long : truncation
if len(signal) >= target_length:
    signal = signal[:target_length]
    
# Si signal trop court : zero-padding
else:
    signal = np.pad(signal, (0, target_length - len(signal)))

# Normalisation Z-score
signal = (signal - np.mean(signal)) / np.std(signal)
```

### Justification

- **Truncation** : Hannun et al. utilisent segments de 30s fixes
- **Zero-padding** : Standard pour longueurs variables (hsd1503/resnet1d)
- **Normalisation** : Am√©liore la stabilit√© d'entra√Ænement (bien que BatchNorm soit utilis√©)

## üìà R√©sultats et comparaisons

### Comparaison avec Hannun et al.

Lors de l'√©valuation, le script compare automatiquement :

```
COMPARISON WITH BENCHMARKS
============================================================

Hannun et al. (2019) - Supplementary Table 7:
  Mean F1-score: 0.836
  Normal: 0.909
  AF: 0.827
  Other: 0.772
  Noisy: 0.506

Current model:
  Mean F1-score: 0.XXX (Œî = ¬±0.XXX)
  ...
```

### Pr√©paration pour Sahu et al. (LTH-ECG)

Une fois que le mod√®le de base atteint les performances de Hannun et al. (~0.836 F1-score), il peut √™tre compress√© avec la m√©thode LTH-ECG de Sahu et al. :

**Objectif de compression** :
- R√©duction de param√®tres : 142√ó (de 10.5M √† ~74K param√®tres)
- Perte de performance : <1% F1-score
- Taille m√©moire : de 115 MB √† ~0.8 MB

## üêõ Debugging et troubleshooting

### Probl√®me : CUDA out of memory

```python
# R√©duire batch size dans config.py
batch_size = 64  # au lieu de 128
```

### Probl√®me : Performance inf√©rieure aux benchmarks

1. **V√©rifier le preprocessing** :
   - Normalisation correcte des signaux
   - Longueur des segments (9000 samples)

2. **Augmenter le nombre d'√©poques** :
   ```python
   max_epochs = 150  # au lieu de 100
   ```

3. **V√©rifier l'√©quilibre des classes** :
   - Le dataset est d√©s√©quilibr√© (60% Normal, 9% AF)
   - Consid√©rer weighted sampling ou class weights

### Probl√®me : Fichiers .mat non trouv√©s

```bash
# V√©rifier la structure des donn√©es
ls data/physionet2017/*.mat | head
cat data/physionet2017/REFERENCE.csv | head
```

## üìö Citations

Si vous utilisez ce code, veuillez citer :

```bibtex
@article{hannun2019cardiologist,
  title={Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network},
  author={Hannun, Awni Y and Rajpurkar, Pranav and Haghpanahi, Masoumeh and Tison, Geoffrey H and Bourn, Codie and Turakhia, Mintu P and Ng, Andrew Y},
  journal={Nature medicine},
  volume={25},
  number={1},
  pages={65--69},
  year={2019}
}

@inproceedings{sahu2022lth,
  title={LTH-ECG: Lottery Ticket Hypothesis-based Deep Learning Model Compression for Atrial Fibrillation Detection from Single Lead ECG On Wearable and Implantable Devices},
  author={Sahu, Ishan and Ukil, Arijit and Khandelwal, Sundeep and Pal, Arpan},
  booktitle={2022 44th Annual International Conference of the IEEE Engineering in Medicine \& Biology Society (EMBC)},
  pages={1655--1658},
  year={2022}
}

@inproceedings{clifford2017af,
  title={AF classification from a short single lead ECG recording: the PhysioNet/computing in cardiology challenge 2017},
  author={Clifford, Gari D and Liu, Chengyu and Moody, Benjamin and Lehman, Li-wei H and Silva, Ikaro and Li, Qiao and Johnson, AE and Mark, Roger G},
  booktitle={2017 Computing in Cardiology (CinC)},
  pages={1--4},
  year={2017}
}
```

## üìû Support

Pour toute question concernant :
- **Dataset** : https://physionet.org/content/challenge-2017/
- **Architecture** : Voir Extended Data Figure 1 dans Hannun et al. (2019)
- **Implementation** : https://github.com/awni/ecg et https://github.com/hsd1503/resnet1d

## üìù License

Ce code est fourni √† des fins de recherche et d'√©ducation. Veuillez respecter les licences des articles et datasets originaux.

## ‚úÖ Checklist de reproduction

- [ ] Dataset PhysioNet 2017 t√©l√©charg√©
- [ ] Environnement Python configur√© (PyTorch, scikit-learn, etc.)
- [ ] Structure des fichiers correcte
- [ ] Entra√Ænement lanc√© avec succ√®s
- [ ] F1-score ‚âà 0.836 (¬±0.01) atteint
- [ ] Visualisations g√©n√©r√©es (confusion matrix, ROC curves)
- [ ] Mod√®le sauvegard√© pour compression future (Sahu et al.)

---

**Note** : Ce projet reproduit la m√©thodologie de Hannun et al. (2019) avec PyTorch. Pour la version TensorFlow originale, voir https://github.com/awni/ecg