{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a973793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from load_data import ECGDataset, ECGCollate, SmartBatchSampler, load_dataset, load_ecg\n",
    "from resnet1d import ResNet1D\n",
    "from mask import Mask\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c89e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(pruning_fraction, pruning_layers_to_ignore: str = None, trained_model = None, current_mask: Mask = None) : \n",
    "    \"\"\"\n",
    "    A one iteration of pruning : returns the new updated mask after pruning.\n",
    "\n",
    "    trained_model : the original fully trained model.\n",
    "    pruning_fraction = The fraction of additional weights to prune from the network.\n",
    "    layers_to_ignore = A comma-separated list of addititonal tensors that should not be pruned.\n",
    "    \"\"\"\n",
    "    current_mask = Mask.ones_like(trained_model).numpy() if current_mask is None else current_mask.numpy()\n",
    "\n",
    "    # Determine the number of weights that need to be pruned.\n",
    "    number_of_remaining_weights = np.sum([np.sum(v) for v in current_mask.values()])\n",
    "    number_of_weights_to_prune = np.ceil(pruning_fraction * number_of_remaining_weights).astype(int)\n",
    "\n",
    "    # Determine which layers can be pruned.\n",
    "    prunable_tensors = set(trained_model.prunable_layer_names)\n",
    "    if pruning_layers_to_ignore:\n",
    "        prunable_tensors -= set(pruning_layers_to_ignore.split(','))\n",
    "    #print(\"prunable_tensors : \\n\", prunable_tensors)\n",
    "    # Get the model weights.\n",
    "    weights = {k: v.clone().cpu().detach().numpy()\n",
    "                for k, v in trained_model.state_dict().items()\n",
    "                if k in prunable_tensors}\n",
    "\n",
    "    # Create a vector of all the unpruned weights in the model.\n",
    "    weight_vector = np.concatenate([v[current_mask[k] == 1] for k, v in weights.items()])\n",
    "    threshold = np.sort(np.abs(weight_vector))[number_of_weights_to_prune]\n",
    "\n",
    "    new_mask = Mask({k: np.where(np.abs(v) > threshold, current_mask[k], np.zeros_like(v))\n",
    "                        for k, v in weights.items()})\n",
    "    for k in current_mask:\n",
    "        if k not in new_mask: # if this weight was already pruned add it to the new mask\n",
    "            new_mask[k] = current_mask[k]\n",
    "\n",
    "    return new_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb08e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrunedModel(nn.Module): \n",
    "    @staticmethod\n",
    "    def to_mask_name(name):\n",
    "        return 'mask_' + name.replace('.', '___')\n",
    "\n",
    "    def __init__(self, model: ResNet1D, mask: Mask):\n",
    "        if isinstance(model, PrunedModel): raise ValueError('Cannot nest pruned models.')\n",
    "        super(PrunedModel, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "        for k in self.model.prunable_layer_names:\n",
    "            if k not in mask: raise ValueError('Missing mask value {}.'.format(k))\n",
    "            if not np.array_equal(mask[k].shape, np.array(self.model.state_dict()[k].shape)):\n",
    "                raise ValueError('Incorrect mask shape {} for tensor {}.'.format(mask[k].shape, k))\n",
    "\n",
    "        for k in mask:\n",
    "            if k not in self.model.prunable_layer_names:\n",
    "                raise ValueError('Key {} found in mask but is not a valid model tensor.'.format(k))\n",
    "\n",
    "        # for k, v in mask.items(): self.register_buffer(PrunedModel.to_mask_name(k), v.float())\n",
    "        # self._apply_mask()\n",
    "        device = next(model.parameters()).device \n",
    "\n",
    "        for k, v in mask.items(): \n",
    "            # On envoie le masque sur le même device que le modèle AVANT de l'enregistrer\n",
    "            self.register_buffer(PrunedModel.to_mask_name(k), v.float().to(device))\n",
    "            \n",
    "        self._apply_mask()\n",
    "\n",
    "    def _apply_mask(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if hasattr(self, PrunedModel.to_mask_name(name)):\n",
    "                param.data *= getattr(self, PrunedModel.to_mask_name(name))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._apply_mask()\n",
    "        return self.model.forward(x)\n",
    "\n",
    "    @property\n",
    "    def prunable_layer_names(self):\n",
    "        return self.model.prunable_layer_names\n",
    "\n",
    "    # @property\n",
    "    # def output_layer_names(self):\n",
    "    #     return self.model.output_layer_names\n",
    "\n",
    "    # @property\n",
    "    # def loss_criterion(self):\n",
    "    #     return self.model.loss_criterion\n",
    "\n",
    "    # def save(self, save_location, save_step):\n",
    "    #     self.model.save(save_location, save_step)\n",
    "\n",
    "    # @staticmethod\n",
    "    # def default_hparams(): raise NotImplementedError()\n",
    "    # @staticmethod\n",
    "    # def is_valid_model_name(model_name): raise NotImplementedError()\n",
    "    # @staticmethod\n",
    "    # def get_model_from_name(model_name, outputs, initializer): raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "325ed667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable),total=len(iterable), ncols=150, desc=desc)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss_func, tb_logger, prior, epochs=10, name=\"default\"):\n",
    "    \"\"\"\n",
    "    Train the classifier for a number of epochs.\n",
    "    \"\"\"\n",
    "    loss_cutoff = len(train_loader) // 10\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "\n",
    "    # Configuration du F1-Score pour 4 classes (N, A, O, ~)\n",
    "    # On utilise 'macro' pour donner autant d'importance à chaque classe\n",
    "    f1_metric = MulticlassF1Score(num_classes=4, average=None).to(device)\n",
    "    best_f1_val = 0.0\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                            mode='min', \n",
    "                                                            factor=0.1, # like in Hannun et al.\n",
    "                                                            patience=2 # 2 in Hannun et al. \"two consecutive epochs\"\n",
    "                                                            )\n",
    "                                                    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Training stage, where we want to update the parameters.\n",
    "        model.train()  # Set the model to training mode\n",
    "\n",
    "        training_loss = []\n",
    "        validation_loss = []\n",
    "        #f1_metric.reset()\n",
    "\n",
    "        # Create a progress bar for the training loop.\n",
    "        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]')\n",
    "        for train_iteration, batch in training_loop:\n",
    "            optimizer.zero_grad() # Reset the gradients - VERY important! Otherwise they accumulate.\n",
    "            ecgs, labels = batch # Get the images and labels from the batch, in the fashion we defined in the dataset and dataloader.\n",
    "            ecgs, labels = ecgs.to(device), labels.to(device) # Send the data to the device (GPU or CPU) - it has to be the same device as the model.\n",
    "\n",
    "\n",
    "            pred = model(ecgs) # Stage 1: Forward().\n",
    "            loss = loss_func(pred, labels) # Compute the loss over the predictions and the ground truth.\n",
    "                    \n",
    "            # DO SOMETHING SIMILAR USING PRUNABLE_LAYERS_NAME\n",
    "            # Computes the gradients and applies the pruning mask to it, this makes sure that all pruned weights are frozen and do not get updated\n",
    "            #loss.backward()\n",
    "            #for layer_name in self.model.get_layer_names():\n",
    "                #layer = self.model.get_layer(layer_name)\n",
    "                #layer.weights.grad *= layer.pruning_mask\n",
    "            #optimizer.step()\n",
    "            #cumulative_loss += loss.item()\n",
    "\n",
    "            loss.backward()  # Stage 2: Backward().\n",
    "\n",
    "            for name, param in model.named_parameters():\n",
    "                if not name.endswith(\".weight\"):\n",
    "                    continue\n",
    "\n",
    "                mask_name = PrunedModel.to_mask_name(name)\n",
    "                if hasattr(model, mask_name):\n",
    "                    mask = getattr(model, mask_name)\n",
    "                    if param.grad is not None:\n",
    "                        param.grad.mul_(mask)\n",
    "                \n",
    "            optimizer.step() # Stage 3: Update the parameters.\n",
    "            # scheduler.step() # Update the learning rate.\n",
    "            # --- LOGIQUE DE PRÉDICTION (Inspirée de votre snippet) ---\n",
    "            with torch.no_grad():\n",
    "                # 1. Softmax + Ajustement par Prior : p / prior\n",
    "                # On transpose pour avoir les classes en dernière dimension : (B, S, C)\n",
    "                 # Sortie probable: (Batch, Classes, Time)\n",
    "                \n",
    "                probs = F.softmax(pred, dim=1).transpose(1, 2)\n",
    "                adjusted_probs = probs / prior\n",
    "                \n",
    "                # 2. Argmax pour obtenir les indices de classes : (B, S)\n",
    "                indices = torch.argmax(adjusted_probs, dim=2)\n",
    "                \n",
    "                # 3. Réduction temporelle par le MODE : (B,)\n",
    "                final_preds, _ = torch.mode(indices, dim=1)\n",
    "                \n",
    "                # 4. Réduction des labels (Batch, Séquence) -> (Batch,)\n",
    "                final_labels = labels[:, 0] if labels.dim() > 1 else labels\n",
    "                \n",
    "                # Mise à jour de la métrique (Tenseurs 1D d'entiers)\n",
    "                f1_metric.update(final_preds, final_labels)\n",
    "\n",
    "            training_loss.append(loss.item())\n",
    "            training_loss = training_loss[-loss_cutoff:]\n",
    "            # Calcul du CINC Average partiel pour la barre de progression\n",
    "            current_f1s = f1_metric.compute()\n",
    "            current_cinc = torch.mean(current_f1s[:3]).item() # Moyenne A, N, O\n",
    "\n",
    "            # Update the progress bar.\n",
    "            training_loop.set_postfix(curr_train_loss = \"{:.8f}\".format(np.mean(training_loss)),\n",
    "                                      curr_train_f1=f\"{current_cinc:.4f}\",\n",
    "                                      lr = \"{:.8f}\".format(optimizer.param_groups[0]['lr'])\n",
    "                                      )\n",
    "\n",
    "            # Update the tensorboard logger.\n",
    "            #tb_logger.add_scalar(f'classifier_{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n",
    "\n",
    "        # Validation stage, where we don't want to update the parameters. Pay attention to the classifier.eval() line\n",
    "        # and \"with torch.no_grad()\" wrapper.\n",
    "        model.eval()\n",
    "        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]')\n",
    "        f1_metric.reset() # Reset pour calculer uniquement la val\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                ecgs, labels = batch\n",
    "                ecgs, labels = ecgs.to(device), labels.to(device)\n",
    "\n",
    "                pred = model(ecgs) # Sortie probable: (Batch, Classes, Time)\n",
    "                \n",
    "                probs = F.softmax(pred, dim=1).transpose(1, 2)\n",
    "                adjusted_probs = probs / prior\n",
    "                \n",
    "                # 2. Argmax pour obtenir les indices de classes : (B, S)\n",
    "                indices = torch.argmax(adjusted_probs, dim=2)\n",
    "                \n",
    "                # 3. Réduction temporelle par le MODE : (B,)\n",
    "                final_preds, _ = torch.mode(indices, dim=1)\n",
    "                \n",
    "                # 4. Réduction des labels (Batch, Séquence) -> (Batch,)\n",
    "                final_labels = labels[:, 0] if labels.dim() > 1 else labels\n",
    "                \n",
    "                # Mise à jour de la métrique (Tenseurs 1D d'entiers)\n",
    "                f1_metric.update(final_preds, final_labels)\n",
    "\n",
    "\n",
    "                validation_loss.append(loss.item())\n",
    "                # Calcul du CINC Average partiel pour la barre de progression\n",
    "                current_val_f1s = f1_metric.compute()\n",
    "                current_val_cinc = torch.mean(current_val_f1s[:3]).item() # Moyenne A, N, O\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(\n",
    "                    val_loss = \"{:.8f}\".format(np.mean(validation_loss)),\n",
    "                    f1_val=f\"{current_val_cinc:.4f}\")\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                #tb_logger.add_scalar(f'classifier_{name}/val_loss', loss.item(), epoch * len(val_loader) + val_iteration)\n",
    "        \n",
    "        \n",
    "        # Calcul final des métriques de l'époque\n",
    "        #epoch_f1_val = f1_metric.compute().item()\n",
    "        \n",
    "        # 3. Récupération des scores par classe (A, N, O, ~)\n",
    "        per_class_f1 = f1_metric.compute() \n",
    "        \n",
    "        # 4. CINC Average : Moyenne des 3 premières classes (A, N, O)\n",
    "        # Comme demandé dans ton snippet : np.mean(scores[2][:3])\n",
    "        cinc_f1 = torch.mean(per_class_f1[:3]).item()\n",
    "\n",
    "\n",
    "        if cinc_f1 > best_f1_val:\n",
    "            best_f1_val = cinc_f1\n",
    "\n",
    "        scheduler.step(np.mean(validation_loss))\n",
    "\n",
    "        # --- LOGIQUE D'EARLY STOPPING ---\n",
    "        # Si le F1 dépasse 82.6% (0.826), on considère que le ticket a convergé avec une tolérance de 1%\n",
    "        # par rapport au 83.6% de l'article\n",
    "        if cinc_f1 >= 0.826:\n",
    "            print(f\"\\n[Early Stopping] F1 Val ({cinc_f1:.4f}) >= 0.826. We stop here, at epoch {epoch:.4f}, the training of the lottery ticket.\")\n",
    "            break\n",
    "    \n",
    "    return model, best_f1_val, epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7791d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_lth_progress(history_theta, history_f1, save_dir=\"plots/\"):\n",
    "    \"\"\"Génère le graphique de performance et le sauvegarde en PNG.\"\"\"\n",
    "    # Création du dossier si inexistant\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, \"lth_performance_plot.png\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Courbe de votre modèle\n",
    "    plt.plot(history_theta, history_f1, 'r-o', label='LTH-ECG (Votre Run)')\n",
    "    \n",
    "    # Benchmark du papier : F1 = 0.836 [cite: 36, 137]\n",
    "    plt.axhline(y=0.836, color='black', linestyle='--', label='Benchmark Papier (0.836)')\n",
    "    \n",
    "    # Seuil de tolérance de 1% (0.836 * 0.99 ≈ 0.827) [cite: 15, 108]\n",
    "    plt.axhline(y=0.827, color='gray', linestyle=':', label='Tolérance 1% (0.827)')\n",
    "    \n",
    "    plt.xlabel('Factor de réduction des paramètres ($\\\\theta$)') \n",
    "    plt.ylabel('Test mean F1-score')\n",
    "    plt.title('Reproduction LTH-ECG : Performance vs Compression')\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "    \n",
    "    # --- MODIFICATION ICI ---\n",
    "\n",
    "    plt.ylim(0.50, 0.95) # Zoom sur la zone d'intérêt [cite: 143-153]\n",
    "    plt.xlim(0, max(max(history_theta), 175)) # Va jusqu'à 175 comme le papier [cite: 159]\n",
    "\n",
    "    # ------------------------\n",
    "\n",
    "    plt.legend(loc='lower left') # Legend en bas à gauche pour ne pas cacher la courbe\n",
    "    \n",
    "    # Sauvegarde physique du fichier\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    print(f\"Graphique mis à jour et sauvegardé dans : {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e2d5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"lth_checkpoint.pth\"):\n",
    "    \"\"\"Saves each step of the pruning process.\"\"\"\n",
    "    print(f\"--> Sauvegarde du checkpoint : {filename}\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename=\"lth_checkpoint.pth\"):\n",
    "    \"\"\"Load one step of the pruning process\"\"\"\n",
    "    print(f\"--> Chargement du checkpoint : {filename}\")\n",
    "    return torch.load(filename, weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "481e20c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.0,\n",
       " 22.02102369832619,\n",
       " 16.624989035011446,\n",
       " 12.876062064966334,\n",
       " 10.20689605863013]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[30**(1/1.1**n) for n in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3267fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priors(train_loader, device, num_classes=4, smooth=500):\n",
    "    \"\"\"Calcule la distribution des classes en gérant les labels séquentiels.\"\"\"\n",
    "    counts = torch.zeros(num_classes)\n",
    "    device = next(iter(train_loader))[1].device # Détection automatique du device\n",
    "    \n",
    "    for _, labels in train_loader:\n",
    "        # Si labels est (Batch, Séquence), on prend le premier label de chaque séquence\n",
    "        if labels.dim() > 1:\n",
    "            # labels[:, 0] récupère le premier label pour chaque échantillon du batch\n",
    "            labels = labels[:, 0]\n",
    "            \n",
    "        for l in labels:\n",
    "            counts[l.long().item()] += 1\n",
    "    \n",
    "    total = counts.sum() + num_classes\n",
    "    prior = (counts + smooth) / total\n",
    "    return prior.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1896bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layerwise_remaining_params(mask,save_dir=\"plots/\") : \n",
    "    # Creates the file if it does not exist already\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, \"layerwise_remaining_params_plot.png\")\n",
    "\n",
    "    # Getting data (might be not in the correct order)\n",
    "    raw_counts = mask.layerwise_remaining_params()\n",
    "\n",
    "    # Ordering data\n",
    "    # On utilise model.prunable_layer_names pour garantir l'ordre séquentiel (Input -> Output)\n",
    "    ordered_layer_names = model.prunable_layer_names\n",
    "    \n",
    "    # On extrait les valeurs dans l'ordre\n",
    "    y_values = []\n",
    "    x_indices = []\n",
    "    \n",
    "    for i, name in enumerate(ordered_layer_names):\n",
    "        if name in raw_counts:\n",
    "            y_values.append(raw_counts[name])\n",
    "            x_indices.append(i + 1) # Figure 2 commence à Layer 1, pas 0 [cite: 171]\n",
    "\n",
    "    # 3. Création du graphique style Figure 2\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Trace la ligne rouge comme dans l'article (\"LTH-ECG (Our)\")\n",
    "    plt.plot(x_indices, y_values, color='red', marker='.', label='LTH-ECG (Our)')\n",
    "    \n",
    "    # Configuration des axes pour matcher l'article\n",
    "    plt.xlabel('Layer Number') \n",
    "    plt.ylabel(\"Remaining parameters, eta'\") \n",
    "    plt.title(\"Reproduction Figure 2 : Remaining parameters per layer\")\n",
    "    \n",
    "    # L'article va jusqu'à la couche 34\n",
    "    plt.xlim(0, 35)\n",
    "    plt.xticks(np.arange(1, 35, step=3)) # Ticks tous les 3 (1, 4, 7...) comme sur l'image source\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Saving the file\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    print(f\"Graphique mis à jour et sauvegardé dans : {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f893f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "                  \"p_init\" : 30,\n",
    "                  \"target_reduction_factor\" : 42, # How much we want to reduce the model's size\n",
    "                  \"alpha\" : 1.1, # Pruning rate's decreasing factor\n",
    "                  \"pruning_layers_to_ignore\" : None\n",
    "                  }\n",
    "\n",
    "\n",
    "def run_lth_ecg(pruning_params, network, train_loader, val_loader, loss_func, resume=False) : \n",
    "    \n",
    "    prior = calculate_priors(train_loader,device,4,500).to(device)\n",
    "    \n",
    "    checkpoint_file = \"lth_ecg_checkpoint_new.pth\"\n",
    "    # Randomly initialize the given DL network D. (quelle initialisation ? Hannun et al. -> \"He normal\")\n",
    "    pruning_percentage = pruning_params[\"p_init\"]\n",
    "    \n",
    "    current_mask = Mask.ones_like(network)\n",
    "    current_mask_np = current_mask.numpy()\n",
    "    initial_weights_number = np.sum([np.sum(v) for v in current_mask_np.values()]) # eta \n",
    "    \n",
    "    print(f\"eta = {initial_weights_number:.2e}\")\n",
    "    # current_model = network\n",
    "    initial_untrained_model = copy.deepcopy(network)\n",
    "    \n",
    "    remaining_weights_number = initial_weights_number\n",
    "    \n",
    "    step = 0\n",
    "\n",
    "    # Listes pour l'historique\n",
    "    history_theta = []\n",
    "    history_f1 = []\n",
    "    early_stopping = []\n",
    "    \n",
    "    ##########\n",
    "    if resume and os.path.exists(checkpoint_file):\n",
    "        checkpoint = load_checkpoint(checkpoint_file)\n",
    "        step = checkpoint['step']\n",
    "        pruning_percentage = checkpoint['pruning_percentage']\n",
    "        current_mask = checkpoint['current_mask']\n",
    "        remaining_weights_number = sum(v.sum().item() for v in current_mask.values())\n",
    "        # On recharge les poids initiaux pour garantir le \"Winning Ticket\" \n",
    "        initial_untrained_model.load_state_dict(checkpoint['initial_weights'])\n",
    "        # On repart du modèle tel qu'il était avant le crash\n",
    "        D = PrunedModel(model=copy.deepcopy(initial_untrained_model), mask=current_mask).to(device)\n",
    "        print(f\"REPRISE à l'étape {step}\")   \n",
    "\n",
    "    else:\n",
    "        D = copy.deepcopy(network)\n",
    "    ##############\n",
    "\n",
    "    # D = copy.deepcopy(network) #current_network\n",
    "    \n",
    "    while (initial_weights_number/remaining_weights_number) < pruning_params[\"target_reduction_factor\"]:\n",
    "        pruning_fraction = pruning_percentage/100\n",
    "        \n",
    "        print(f\"\\n{'='*30} STEP {step} {'='*30}\")\n",
    "        print(f\"remaining_weights_number = {remaining_weights_number:.2e}\")\n",
    "        print(\"current reduction factor = \", np.round(initial_weights_number/remaining_weights_number, 2), ' over 42')\n",
    "        print(\"pruning percentage = \", np.round(pruning_percentage,2), ' %')\n",
    "        print(\"pruning fraction = \", np.round(pruning_fraction,2))\n",
    "        print(\"model sparcity (percentage of weight that has been pruned): \", current_mask.sparsity )  \n",
    "        # Train the DL network with the given data x.\n",
    "        D,final_f1, epoch = train_model(D, train_loader, val_loader, loss_func, name = \"lth_ecg\", prior = prior, epochs=20,tb_logger=None)\n",
    "        print('final_f1', final_f1)\n",
    "        # 3. Archivage\n",
    "        history_theta.append(initial_weights_number/remaining_weights_number)\n",
    "        history_f1.append(final_f1)\n",
    "        early_stopping.append(epoch)\n",
    "\n",
    "        # 4. Affichage toutes les 5 steps\n",
    "        if step % 5 == 0:\n",
    "            plot_lth_progress(history_theta, history_f1)\n",
    "            plot_layerwise_remaining_params(current_mask)\n",
    "            \n",
    "        if isinstance(D, PrunedModel):\n",
    "            model_to_prune = D.model\n",
    "        else:\n",
    "            model_to_prune = D\n",
    "\n",
    "        # Prune p_init% of weights which are of least magnitude\n",
    "        #new_mask = prune(pruning_fraction, pruning_params[\"pruning_layers_to_ignore\"], D)\n",
    "        new_mask = prune(pruning_fraction, pruning_params[\"pruning_layers_to_ignore\"], model_to_prune, current_mask)\n",
    "        #print(\"new_mask is a mask ? \", isinstance(new_mask, Mask))\n",
    "        # print(\"new_mask : \\n \", new_mask)\n",
    "        \n",
    "\n",
    "        pred = D_sparse(ecgs) # Sortie probable: (Batch, Classes, Time)\n",
    "\n",
    "        probs = F.softmax(pred, dim=1).transpose(1, 2)\n",
    "        adjusted_probs = probs / prior\n",
    "                \n",
    "        # 2. Argmax pour obtenir les indices de classes : (B, S)\n",
    "        indices = torch.argmax(adjusted_probs, dim=2)\n",
    "                \n",
    "        # 3. Réduction temporelle par le MODE : (B,)\n",
    "        final_preds, _ = torch.mode(indices, dim=1)\n",
    "                \n",
    "        # 4. Réduction des labels (Batch, Séquence) -> (Batch,)\n",
    "        final_labels = labels[:, 0] if labels.dim() > 1 else labels\n",
    "                \n",
    "        # Mise à jour de la métrique (Tenseurs 1D d'entiers)\n",
    "        f1_metric.update(final_preds, final_labels)\n",
    "\n",
    "        # Computation of the partial CINC Average for the progress bar\n",
    "        current_val_f1s = f1_metric.compute()\n",
    "        current_val_cinc = torch.mean(current_val_f1s[:3]).item() # Mean on A, N, O\n",
    "        # Update the progress bar.\n",
    "        val_loop.set_postfix(\n",
    "            f1_val=f\"{current_val_cinc:.4f}\")\n",
    "        \n",
    "        history_f1.append(current_val_cinc)\n",
    "\n",
    "        # Plots and push of checkpoints on github every 5 steps \n",
    "        if step % 5 == 0:\n",
    "            plot_lth_progress(history_theta, history_f1, 'plots/lth_ecg/')\n",
    "            plot_layerwise_remaining_params(D_sparse, current_mask, 'plots/lth_ecg/')\n",
    "            # push_checkpoint_to_git(\n",
    "            #         filepaths=[checkpoint_file,\"plots/lth_performance_plot.png\",\"plots/layerwise_remaining_params_plot.png\"],\n",
    "            #         branch_name=\"felix-v3\",  # Mets le nom de ta branche ici\n",
    "            #         commit_msg=f\"Auto save checkpoints and plots step {step-1}\"\n",
    "            #     )\n",
    "\n",
    "        # Update pruning percentage (alpha = 1.1)\n",
    "        pruning_percentage = pruning_percentage**(1/1.1)\n",
    "        # reset unpruned weights to their initial random values and D = D_sparse\n",
    "        D = PrunedModel(model=copy.deepcopy(initial_untrained_model), mask=new_mask).to(device)\n",
    "        \n",
    "        # remaining_weights_number = # On utilise la somme native de Python, et .item() pour extraire la valeur du tenseur\n",
    "        remaining_weights_number = sum(v.sum().item() for v in new_mask.values())\n",
    "        # print(\"just before current_mask = new_mask new_mask is a mask ? \", isinstance(new_mask, Mask))\n",
    "        # print(\"just before current_mask = new_mask current_mask is a mask ? \", isinstance(current_mask, Mask))\n",
    "        current_mask = new_mask\n",
    "        # print(\"just after current_mask = new_mask current_mask is a mask ? \", isinstance(current_mask, Mask))\n",
    "        # print(\"just after current_mask = new_mask current_mask is a dict ? \", isinstance(current_mask, dict))\n",
    "        step+=1\n",
    "        # --- SAUVEGARDE DE SÉCURITÉ ---\n",
    "        checkpoint_state = {\n",
    "            'step': step,\n",
    "            'pruning_percentage': pruning_percentage,\n",
    "            'current_mask': current_mask,\n",
    "            'initial_weights': initial_untrained_model.state_dict(),\n",
    "            'reduction_factor': initial_weights_number / remaining_weights_number,\n",
    "            'history_theta': history_theta,\n",
    "            'history_f1': history_f1,\n",
    "            'layerwise_sparcity': current_mask.layerwise_sparsity(),\n",
    "            'layerwise_remaining_params': current_mask.layerwise_remaining_params(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint_state, filename=checkpoint_file)\n",
    "\n",
    "        print(\"=\"*60, \"\\n\")\n",
    "        \n",
    "\n",
    "    # Plot final à la fin de l'expérience\n",
    "    #plot_lth_progress(history_theta, history_f1, save_dir = 'plots/lth_ecg/')\n",
    "\n",
    "    return current_mask, history_theta, history_f1, early_stopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "140463d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "                  \"p_init\" : 30,\n",
    "                  \"target_reduction_factor\" : 42, # to reach a 1 MB model size\n",
    "                  \"alpha\" : 1.1,\n",
    "                  \"pruning_layers_to_ignore\" : None\n",
    "                  }\n",
    "\n",
    "\n",
    "def run_lth_ecg_2(pruning_params, network, train_loader, val_loader, loss_func, resume=False) : \n",
    "    \n",
    "    prior = calculate_priors(train_loader,device,4,500).to(device)\n",
    "    \n",
    "    checkpoint_file = \"new_lth_ecg_checkpoint.pth\"\n",
    "    \n",
    "    # Randomly initialize the given DL network D. (quelle initialisation ? Hannun et al. -> \"He normal\")\n",
    "    pruning_percentage = pruning_params[\"p_init\"]\n",
    "    \n",
    "    current_mask = Mask.ones_like(network)\n",
    "    current_mask_np = current_mask.numpy()\n",
    "    initial_weights_number = np.sum([np.sum(v) for v in current_mask_np.values()]) # eta \n",
    "    \n",
    "    initial_untrained_model = copy.deepcopy(network)\n",
    "    \n",
    "    remaining_weights_number = initial_weights_number\n",
    "    \n",
    "    f1_metric = MulticlassF1Score(num_classes=4, average=None).to(device)\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    # Listes pour l'historique\n",
    "    history_theta = []\n",
    "    history_f1 = []\n",
    "    history_sparsity = []\n",
    "    early_stopping = []\n",
    "\n",
    "    ##########\n",
    "    if resume and os.path.exists(checkpoint_file):\n",
    "        checkpoint = load_checkpoint(checkpoint_file)\n",
    "        step = checkpoint['step']\n",
    "        pruning_percentage = checkpoint['pruning_percentage']\n",
    "        current_mask = checkpoint['current_mask']\n",
    "        history_theta = checkpoint['history_theta']\n",
    "        history_f1 = checkpoint['history_f1']\n",
    "        history_sparsity = checkpoint['history_sparsity']\n",
    "        remaining_weights_number = sum(v.sum().item() for v in current_mask.values())\n",
    "        # On recharge les poids initiaux pour garantir le \"Winning Ticket\" \n",
    "        initial_untrained_model.load_state_dict(checkpoint['initial_weights'])\n",
    "        # On repart du modèle tel qu'il était avant le crash\n",
    "        D = PrunedModel(model=copy.deepcopy(initial_untrained_model), mask=current_mask).to(device)\n",
    "        print(f\"REPRISE à l'étape {step}\")   \n",
    "\n",
    "    else:\n",
    "        D = copy.deepcopy(network)\n",
    "    ##############\n",
    "\n",
    "    \n",
    "    while (initial_weights_number/remaining_weights_number) < pruning_params[\"target_reduction_factor\"]:\n",
    "        pruning_fraction = pruning_percentage/100\n",
    "        \n",
    "        print(f\"\\n{'='*30} STEP {step} {'='*30}\")\n",
    "        print(f\"remaining_weights_number = {remaining_weights_number:.2e}\")\n",
    "        print(\"current reduction factor = \", np.round(initial_weights_number/remaining_weights_number, 2), ' over 42')\n",
    "        print(\"pruning percentage = \", np.round(pruning_percentage,2), ' %')\n",
    "        print(\"pruning fraction = \", np.round(pruning_fraction,2))\n",
    "        print(\"model sparcity (percentage of weight that has been pruned): \", current_mask.sparsity )  \n",
    "        # Train the DL network with the given data x.\n",
    "        D,final_f1, stop = train_model(D, train_loader, val_loader, loss_func, name = \"lth_ecg\", prior = prior, epochs=20,tb_logger=None)\n",
    "\n",
    "        # 3. Archivage\n",
    "        history_theta.append(initial_weights_number/remaining_weights_number)\n",
    "        \n",
    "        history_sparsity.append(current_mask.sparsity)\n",
    "        early_stopping.append(stop)\n",
    "        \n",
    "        if isinstance(D, PrunedModel):\n",
    "            model_to_prune = D.model\n",
    "        else:\n",
    "            model_to_prune = D\n",
    "\n",
    "        # Prune p_init% of weights which are of least magnitude\n",
    "    \n",
    "        new_mask = prune(pruning_fraction, pruning_params[\"pruning_layers_to_ignore\"], model_to_prune, current_mask)\n",
    "\n",
    "        D_sparse = PrunedModel(model=model_to_prune,mask = new_mask).to(device)\n",
    "\n",
    "        # Validation\n",
    "        D_sparse.eval()\n",
    "        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Sparse Model [step : {step}]')\n",
    "        f1_metric.reset() # Reset pour calculer uniquement la val\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                ecgs, labels = batch\n",
    "                ecgs, labels = ecgs.to(device), labels.to(device)\n",
    "\n",
    "                pred = D_sparse(ecgs) # Sortie probable: (Batch, Classes, Time)\n",
    "\n",
    "                probs = F.softmax(pred, dim=1).transpose(1, 2)\n",
    "                adjusted_probs = probs / prior\n",
    "                \n",
    "                # 2. Argmax pour obtenir les indices de classes : (B, S)\n",
    "                indices = torch.argmax(adjusted_probs, dim=2)\n",
    "                \n",
    "                # 3. Réduction temporelle par le MODE : (B,)\n",
    "                final_preds, _ = torch.mode(indices, dim=1)\n",
    "                \n",
    "                # 4. Réduction des labels (Batch, Séquence) -> (Batch,)\n",
    "                final_labels = labels[:, 0] if labels.dim() > 1 else labels\n",
    "                \n",
    "                # Mise à jour de la métrique (Tenseurs 1D d'entiers)\n",
    "                f1_metric.update(final_preds, final_labels)\n",
    "\n",
    "                # Calcul du CINC Average partiel pour la barre de progression\n",
    "                current_val_f1s = f1_metric.compute()\n",
    "                current_val_cinc = torch.mean(current_val_f1s[:3]).item() # Moyenne A, N, O\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(\n",
    "                    f1_val=f\"{current_val_cinc:.4f}\")\n",
    "        \n",
    "        history_f1.append(current_val_cinc)\n",
    "\n",
    "        # Plots and push of checkpoints on github every 5 steps \n",
    "        #if step % 5 == 0:\n",
    "            #plot_lth_progress(history_theta, history_f1, 'plots/lth_ecg/')\n",
    "            #plot_layerwise_remaining_params(D_sparse, current_mask, 'plots/lth_ecg/')\n",
    "            # push_checkpoint_to_git(\n",
    "            #         filepaths=[checkpoint_file,\"plots/lth_performance_plot.png\",\"plots/layerwise_remaining_params_plot.png\"],\n",
    "            #         branch_name=\"felix-v3\",  # Mets le nom de ta branche ici\n",
    "            #         commit_msg=f\"Auto save checkpoints and plots step {step-1}\"\n",
    "            #     )\n",
    "\n",
    "        # Update pruning percentage (alpha = 1.1)\n",
    "        pruning_percentage = pruning_percentage**(1/1.1)\n",
    "\n",
    "        # reset unpruned weights to their initial random values and D = D_sparse\n",
    "        D = PrunedModel(model=copy.deepcopy(initial_untrained_model), mask=new_mask).to(device)\n",
    "        \n",
    "        remaining_weights_number = sum(v.sum().item() for v in new_mask.values())\n",
    "       \n",
    "        current_mask = new_mask\n",
    "       \n",
    "        step+=1\n",
    "\n",
    "        # --- SAUVEGARDE DE SÉCURITÉ ---\n",
    "        checkpoint_state = {\n",
    "            'step': step,\n",
    "            'pruning_percentage': pruning_percentage,\n",
    "            'current_mask': current_mask,\n",
    "            'initial_weights': initial_untrained_model.state_dict(),\n",
    "            'reduction_factor': initial_weights_number / remaining_weights_number,\n",
    "            'history_theta': history_theta,\n",
    "            'history_f1': history_f1,\n",
    "            'history_sparsity': history_sparsity,\n",
    "            'layerwise_sparcity': current_mask.layerwise_sparsity(),\n",
    "            'layerwise_remaining_params': current_mask.layerwise_remaining_params()\n",
    "        }\n",
    "        save_checkpoint(checkpoint_state, filename=checkpoint_file)\n",
    "\n",
    "        print(\"=\"*60, \"\\n\")\n",
    "        \n",
    "\n",
    "    # Plot final à la fin de l'expérience\n",
    "    plot_lth_progress(history_theta, history_f1, save_dir = 'plots/lth_ecg/')\n",
    "\n",
    "    return current_mask, history_theta, history_f1, early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e9c9a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7676/7676 [00:21<00:00, 362.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dev set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:02<00:00, 345.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN :  7.4661856  STD :  236.10312\n",
      "self.classes :  ['A', 'N', 'O', '~']\n",
      "self.class_to_int :  {'A': 0, 'N': 1, 'O': 2, '~': 3}\n",
      "MEAN :  8.029898  STD :  242.35907\n",
      "self.classes :  ['A', 'N', 'O', '~']\n",
      "self.class_to_int :  {'A': 0, 'N': 1, 'O': 2, '~': 3}\n",
      "Tri du dataset par longueur pour minimiser le padding...\n",
      "Tri du dataset par longueur pour minimiser le padding...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training set...\")\n",
    "train = load_dataset(\"train.json\",256)\n",
    "train_ecgs, train_labels = train\n",
    "# reduciton of size to improve training time\n",
    "# train_ecgs, train_labels = train_ecgs[:1000], train_labels[:1000]\n",
    "print(\"Loading dev set...\")\n",
    "val_ecgs,val_labels = load_dataset(\"dev.json\",256)\n",
    "# reduciton of size to improve training time\n",
    "# val_ecgs, val_labels = val_ecgs[:100], val_labels[:100]\n",
    "\n",
    "train_dataset = ECGDataset(train_ecgs, train_labels)\n",
    "val_dataset = ECGDataset(val_ecgs, val_labels)\n",
    "\n",
    "# Instanciation du Sampler intelligent\n",
    "train_batch_sampler = SmartBatchSampler(train_dataset, 32)\n",
    "val_batch_sampler = SmartBatchSampler(val_dataset, 32)\n",
    "\n",
    "train_collate_fn = ECGCollate(\n",
    "    pad_val_x=train_dataset.pad_value_x_normalized,\n",
    "    num_classes=train_dataset.num_classes\n",
    ")\n",
    "\n",
    "val_collate_fn = ECGCollate(\n",
    "    pad_val_x=val_dataset.pad_value_x_normalized,\n",
    "    num_classes=val_dataset.num_classes\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler=train_batch_sampler, \n",
    "    collate_fn=train_collate_fn,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_sampler=val_batch_sampler, \n",
    "    collate_fn=val_collate_fn,\n",
    "    num_workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21393819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n",
    "\n",
    "# make model\n",
    "device_str = \"cuda\"\n",
    "device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "kernel_size = 16 # 16 in Hannun et al.\n",
    "stride = 2\n",
    "n_block = 16 # 16 in Hannun et al.\n",
    "downsample_gap = 2 # 2 in Hannun et al.\n",
    "increasefilter_gap = 4 # 4 in Hannun et al.\n",
    "\n",
    "model = ResNet1D(\n",
    "    in_channels=1, \n",
    "    base_filters=32, # 32 in Hannun et al.\n",
    "    kernel_size=kernel_size, \n",
    "    stride=stride, \n",
    "    groups=1, # like a classical ResNet\n",
    "    n_block=n_block, \n",
    "    n_classes=4, \n",
    "    downsample_gap=downsample_gap, \n",
    "    increasefilter_gap=increasefilter_gap, \n",
    "    use_bn=True,\n",
    "    use_do=True,\n",
    "    verbose = False\n",
    "    ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b9a3fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 32, 100]             544\n",
      "   MyConv1dPadSame-2              [-1, 32, 100]               0\n",
      "       BatchNorm1d-3              [-1, 32, 100]              64\n",
      "              ReLU-4              [-1, 32, 100]               0\n",
      "            Conv1d-5              [-1, 32, 100]          16,416\n",
      "   MyConv1dPadSame-6              [-1, 32, 100]               0\n",
      "       BatchNorm1d-7              [-1, 32, 100]              64\n",
      "              ReLU-8              [-1, 32, 100]               0\n",
      "           Dropout-9              [-1, 32, 100]               0\n",
      "           Conv1d-10              [-1, 32, 100]          16,416\n",
      "  MyConv1dPadSame-11              [-1, 32, 100]               0\n",
      "       BasicBlock-12              [-1, 32, 100]               0\n",
      "      BatchNorm1d-13              [-1, 32, 100]              64\n",
      "             ReLU-14              [-1, 32, 100]               0\n",
      "           Conv1d-15               [-1, 32, 50]          16,416\n",
      "  MyConv1dPadSame-16               [-1, 32, 50]               0\n",
      "      BatchNorm1d-17               [-1, 32, 50]              64\n",
      "             ReLU-18               [-1, 32, 50]               0\n",
      "          Dropout-19               [-1, 32, 50]               0\n",
      "           Conv1d-20               [-1, 32, 50]          16,416\n",
      "  MyConv1dPadSame-21               [-1, 32, 50]               0\n",
      "        MaxPool1d-22               [-1, 32, 50]               0\n",
      "MyMaxPool1dPadSame-23               [-1, 32, 50]               0\n",
      "       BasicBlock-24               [-1, 32, 50]               0\n",
      "      BatchNorm1d-25               [-1, 32, 50]              64\n",
      "             ReLU-26               [-1, 32, 50]               0\n",
      "           Conv1d-27               [-1, 32, 50]          16,416\n",
      "  MyConv1dPadSame-28               [-1, 32, 50]               0\n",
      "      BatchNorm1d-29               [-1, 32, 50]              64\n",
      "             ReLU-30               [-1, 32, 50]               0\n",
      "          Dropout-31               [-1, 32, 50]               0\n",
      "           Conv1d-32               [-1, 32, 50]          16,416\n",
      "  MyConv1dPadSame-33               [-1, 32, 50]               0\n",
      "       BasicBlock-34               [-1, 32, 50]               0\n",
      "      BatchNorm1d-35               [-1, 32, 50]              64\n",
      "             ReLU-36               [-1, 32, 50]               0\n",
      "           Conv1d-37               [-1, 32, 25]          16,416\n",
      "  MyConv1dPadSame-38               [-1, 32, 25]               0\n",
      "      BatchNorm1d-39               [-1, 32, 25]              64\n",
      "             ReLU-40               [-1, 32, 25]               0\n",
      "          Dropout-41               [-1, 32, 25]               0\n",
      "           Conv1d-42               [-1, 32, 25]          16,416\n",
      "  MyConv1dPadSame-43               [-1, 32, 25]               0\n",
      "        MaxPool1d-44               [-1, 32, 25]               0\n",
      "MyMaxPool1dPadSame-45               [-1, 32, 25]               0\n",
      "       BasicBlock-46               [-1, 32, 25]               0\n",
      "      BatchNorm1d-47               [-1, 32, 25]              64\n",
      "             ReLU-48               [-1, 32, 25]               0\n",
      "           Conv1d-49               [-1, 64, 25]          32,832\n",
      "  MyConv1dPadSame-50               [-1, 64, 25]               0\n",
      "      BatchNorm1d-51               [-1, 64, 25]             128\n",
      "             ReLU-52               [-1, 64, 25]               0\n",
      "          Dropout-53               [-1, 64, 25]               0\n",
      "           Conv1d-54               [-1, 64, 25]          65,600\n",
      "  MyConv1dPadSame-55               [-1, 64, 25]               0\n",
      "       BasicBlock-56               [-1, 64, 25]               0\n",
      "      BatchNorm1d-57               [-1, 64, 25]             128\n",
      "             ReLU-58               [-1, 64, 25]               0\n",
      "           Conv1d-59               [-1, 64, 13]          65,600\n",
      "  MyConv1dPadSame-60               [-1, 64, 13]               0\n",
      "      BatchNorm1d-61               [-1, 64, 13]             128\n",
      "             ReLU-62               [-1, 64, 13]               0\n",
      "          Dropout-63               [-1, 64, 13]               0\n",
      "           Conv1d-64               [-1, 64, 13]          65,600\n",
      "  MyConv1dPadSame-65               [-1, 64, 13]               0\n",
      "        MaxPool1d-66               [-1, 64, 13]               0\n",
      "MyMaxPool1dPadSame-67               [-1, 64, 13]               0\n",
      "       BasicBlock-68               [-1, 64, 13]               0\n",
      "      BatchNorm1d-69               [-1, 64, 13]             128\n",
      "             ReLU-70               [-1, 64, 13]               0\n",
      "           Conv1d-71               [-1, 64, 13]          65,600\n",
      "  MyConv1dPadSame-72               [-1, 64, 13]               0\n",
      "      BatchNorm1d-73               [-1, 64, 13]             128\n",
      "             ReLU-74               [-1, 64, 13]               0\n",
      "          Dropout-75               [-1, 64, 13]               0\n",
      "           Conv1d-76               [-1, 64, 13]          65,600\n",
      "  MyConv1dPadSame-77               [-1, 64, 13]               0\n",
      "       BasicBlock-78               [-1, 64, 13]               0\n",
      "      BatchNorm1d-79               [-1, 64, 13]             128\n",
      "             ReLU-80               [-1, 64, 13]               0\n",
      "           Conv1d-81                [-1, 64, 7]          65,600\n",
      "  MyConv1dPadSame-82                [-1, 64, 7]               0\n",
      "      BatchNorm1d-83                [-1, 64, 7]             128\n",
      "             ReLU-84                [-1, 64, 7]               0\n",
      "          Dropout-85                [-1, 64, 7]               0\n",
      "           Conv1d-86                [-1, 64, 7]          65,600\n",
      "  MyConv1dPadSame-87                [-1, 64, 7]               0\n",
      "        MaxPool1d-88                [-1, 64, 7]               0\n",
      "MyMaxPool1dPadSame-89                [-1, 64, 7]               0\n",
      "       BasicBlock-90                [-1, 64, 7]               0\n",
      "      BatchNorm1d-91                [-1, 64, 7]             128\n",
      "             ReLU-92                [-1, 64, 7]               0\n",
      "           Conv1d-93               [-1, 128, 7]         131,200\n",
      "  MyConv1dPadSame-94               [-1, 128, 7]               0\n",
      "      BatchNorm1d-95               [-1, 128, 7]             256\n",
      "             ReLU-96               [-1, 128, 7]               0\n",
      "          Dropout-97               [-1, 128, 7]               0\n",
      "           Conv1d-98               [-1, 128, 7]         262,272\n",
      "  MyConv1dPadSame-99               [-1, 128, 7]               0\n",
      "      BasicBlock-100               [-1, 128, 7]               0\n",
      "     BatchNorm1d-101               [-1, 128, 7]             256\n",
      "            ReLU-102               [-1, 128, 7]               0\n",
      "          Conv1d-103               [-1, 128, 4]         262,272\n",
      " MyConv1dPadSame-104               [-1, 128, 4]               0\n",
      "     BatchNorm1d-105               [-1, 128, 4]             256\n",
      "            ReLU-106               [-1, 128, 4]               0\n",
      "         Dropout-107               [-1, 128, 4]               0\n",
      "          Conv1d-108               [-1, 128, 4]         262,272\n",
      " MyConv1dPadSame-109               [-1, 128, 4]               0\n",
      "       MaxPool1d-110               [-1, 128, 4]               0\n",
      "MyMaxPool1dPadSame-111               [-1, 128, 4]               0\n",
      "      BasicBlock-112               [-1, 128, 4]               0\n",
      "     BatchNorm1d-113               [-1, 128, 4]             256\n",
      "            ReLU-114               [-1, 128, 4]               0\n",
      "          Conv1d-115               [-1, 128, 4]         262,272\n",
      " MyConv1dPadSame-116               [-1, 128, 4]               0\n",
      "     BatchNorm1d-117               [-1, 128, 4]             256\n",
      "            ReLU-118               [-1, 128, 4]               0\n",
      "         Dropout-119               [-1, 128, 4]               0\n",
      "          Conv1d-120               [-1, 128, 4]         262,272\n",
      " MyConv1dPadSame-121               [-1, 128, 4]               0\n",
      "      BasicBlock-122               [-1, 128, 4]               0\n",
      "     BatchNorm1d-123               [-1, 128, 4]             256\n",
      "            ReLU-124               [-1, 128, 4]               0\n",
      "          Conv1d-125               [-1, 128, 2]         262,272\n",
      " MyConv1dPadSame-126               [-1, 128, 2]               0\n",
      "     BatchNorm1d-127               [-1, 128, 2]             256\n",
      "            ReLU-128               [-1, 128, 2]               0\n",
      "         Dropout-129               [-1, 128, 2]               0\n",
      "          Conv1d-130               [-1, 128, 2]         262,272\n",
      " MyConv1dPadSame-131               [-1, 128, 2]               0\n",
      "       MaxPool1d-132               [-1, 128, 2]               0\n",
      "MyMaxPool1dPadSame-133               [-1, 128, 2]               0\n",
      "      BasicBlock-134               [-1, 128, 2]               0\n",
      "     BatchNorm1d-135               [-1, 128, 2]             256\n",
      "            ReLU-136               [-1, 128, 2]               0\n",
      "          Conv1d-137               [-1, 256, 2]         524,544\n",
      " MyConv1dPadSame-138               [-1, 256, 2]               0\n",
      "     BatchNorm1d-139               [-1, 256, 2]             512\n",
      "            ReLU-140               [-1, 256, 2]               0\n",
      "         Dropout-141               [-1, 256, 2]               0\n",
      "          Conv1d-142               [-1, 256, 2]       1,048,832\n",
      " MyConv1dPadSame-143               [-1, 256, 2]               0\n",
      "      BasicBlock-144               [-1, 256, 2]               0\n",
      "     BatchNorm1d-145               [-1, 256, 2]             512\n",
      "            ReLU-146               [-1, 256, 2]               0\n",
      "          Conv1d-147               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-148               [-1, 256, 1]               0\n",
      "     BatchNorm1d-149               [-1, 256, 1]             512\n",
      "            ReLU-150               [-1, 256, 1]               0\n",
      "         Dropout-151               [-1, 256, 1]               0\n",
      "          Conv1d-152               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-153               [-1, 256, 1]               0\n",
      "       MaxPool1d-154               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-155               [-1, 256, 1]               0\n",
      "      BasicBlock-156               [-1, 256, 1]               0\n",
      "     BatchNorm1d-157               [-1, 256, 1]             512\n",
      "            ReLU-158               [-1, 256, 1]               0\n",
      "          Conv1d-159               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-160               [-1, 256, 1]               0\n",
      "     BatchNorm1d-161               [-1, 256, 1]             512\n",
      "            ReLU-162               [-1, 256, 1]               0\n",
      "         Dropout-163               [-1, 256, 1]               0\n",
      "          Conv1d-164               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-165               [-1, 256, 1]               0\n",
      "      BasicBlock-166               [-1, 256, 1]               0\n",
      "     BatchNorm1d-167               [-1, 256, 1]             512\n",
      "            ReLU-168               [-1, 256, 1]               0\n",
      "          Conv1d-169               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-170               [-1, 256, 1]               0\n",
      "     BatchNorm1d-171               [-1, 256, 1]             512\n",
      "            ReLU-172               [-1, 256, 1]               0\n",
      "         Dropout-173               [-1, 256, 1]               0\n",
      "          Conv1d-174               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-175               [-1, 256, 1]               0\n",
      "       MaxPool1d-176               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-177               [-1, 256, 1]               0\n",
      "      BasicBlock-178               [-1, 256, 1]               0\n",
      "     BatchNorm1d-179               [-1, 256, 1]             512\n",
      "            ReLU-180               [-1, 256, 1]               0\n",
      "          Conv1d-181                 [-1, 4, 1]           1,028\n",
      "================================================================\n",
      "Total params: 10,466,148\n",
      "Trainable params: 10,466,148\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.27\n",
      "Params size (MB): 39.93\n",
      "Estimated Total Size (MB): 41.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1,100), device=device_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "434471d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphique mis à jour et sauvegardé dans : plots/lth_ecg/lth_performance_plot.png\n"
     ]
    }
   ],
   "source": [
    "final_mask, history_theta, history_f1, early_stopping = run_lth_ecg_2(pruning_params, model, train_loader, val_loader, loss_func, resume = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire un truc qui permet de push directemnt sur git hub de temps en temps\n",
    "# ajouter le nombre de MB que fait le modèle au fur-et-à-mesure, ça se trouve les 1 mb ne sont pas si loin\n",
    "# il faut rabouter les history_f1 et history_theta chargé dans les checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
