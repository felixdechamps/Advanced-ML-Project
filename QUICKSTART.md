# üöÄ Guide de D√©marrage Rapide

Guide pas-√†-pas pour reproduire les r√©sultats de Hannun et al. (2019) sur le dataset PhysioNet 2017.

## ‚ö° Installation en 5 minutes

### 1. Cloner/Cr√©er le projet

```bash
# Cr√©er la structure de r√©pertoires
mkdir -p ecg_classification/{data,models,utils,checkpoints,logs,results}
cd ecg_classification

# Copier tous les fichiers Python fournis dans leurs r√©pertoires respectifs
```

### 2. Installer les d√©pendances

```bash
# Cr√©er un environnement virtuel (recommand√©)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les packages
pip install -r requirements.txt
```

### 3. T√©l√©charger les donn√©es

**Option A : Script automatique (Linux/Mac)**
```bash
chmod +x download_data.sh
./download_data.sh
```

**Option B : Manuel**
```bash
mkdir -p data/physionet2017
cd data/physionet2017

# T√©l√©charger
wget -r -N -c -np --cut-dirs=3 --reject "index.html*" \
  https://physionet.org/files/challenge-2017/1.0.0/training2017/

# D√©placer les fichiers
mv training2017/* .
rmdir training2017

cd ../..
```

### 4. Tester l'installation

```bash
python test_setup.py
```

Vous devriez voir :
```
‚úì PASS: Imports
‚úì PASS: PyTorch
‚úì PASS: Model Architecture
‚úì PASS: Dataset Loading
‚úì PASS: Metrics
‚úì PASS: Training Utilities

Total: 6/6 tests passed
‚úì All tests passed! Ready to train.
```

## üéØ Entra√Ænement du mod√®le

### Entra√Ænement complet

```bash
python train.py
```

**Ce que fait le script** :
- Charge le dataset PhysioNet 2017 (8,528 √©chantillons)
- Split 90% train / 10% validation (Hannun et al.)
- Initialise ResNet1D 34 couches avec He initialization
- Entra√Æne avec Adam (Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999, LR=1e-3)
- R√©duit LR par 10 si validation loss stagne 2 √©poques
- Sauvegarde le meilleur mod√®le bas√© sur F1-score
- Early stopping apr√®s 10 √©poques sans am√©lioration

**Dur√©e estim√©e** :
- GPU (NVIDIA RTX 3080) : 2-4 heures
- GPU (NVIDIA T4) : 4-8 heures  
- CPU : 24-48 heures (non recommand√©)

**R√©sultats attendus** :
```
Epoch 50/100
------------------------------------------------------------
Train Loss: 0.2134
Val Loss:   0.2456
Val F1:     0.8354
Learning Rate: 0.000010

‚úì New best model! F1: 0.8354
```

### Reprendre un entra√Ænement interrompu

```bash
python train.py --resume checkpoints/best_model.pth
```

## üìä √âvaluation du mod√®le

### √âvaluation basique

```bash
python evaluate.py --checkpoint checkpoints/best_model.pth
```

### √âvaluation avec visualisations

```bash
python evaluate.py \
  --checkpoint checkpoints/best_model.pth \
  --plot \
  --save-results \
  --output-dir results/
```

**R√©sultats attendus** (Hannun et al. Supplementary Table 7) :

```
============================================================
EVALUATION METRICS
============================================================

Overall Metrics:
  Accuracy:        0.8923
  F1 (macro):      0.8360
  F1 (weighted):   0.8891
  Precision:       0.8456
  Recall:          0.8312
  AUC (macro):     0.9700

Per-Class Metrics:
Class           F1        Precision    Recall  Specificity      AUC
------------------------------------------------------------
Normal          0.9090       0.9124    0.9056       0.8712   0.9750
AF              0.8270       0.8401    0.8142       0.9780   0.9650
Other           0.7720       0.7834    0.7608       0.9234   0.9580
Noisy           0.5060       0.5201    0.4924       0.9956   0.8920
============================================================

COMPARISON WITH BENCHMARKS
============================================================

Hannun et al. (2019) - Supplementary Table 7:
  Mean F1-score: 0.836

Current model:
  Mean F1-score: 0.836 (Œî = +0.000)

‚úì Performance matches Hannun et al. benchmark!
  Ready for model compression (Sahu et al. LTH-ECG)
```

## üóúÔ∏è Compression du mod√®le (LTH-ECG)

Une fois le mod√®le de base entra√Æn√© et valid√© :

```python
from models.resnet1d import ResNet1d
from lth_ecg import LTHECGPruner
from config import Config
import torch

# Charger le mod√®le entra√Æn√©
config = Config()
model = ResNet1d(
    in_channels=1,
    base_filters=config.base_filters,
    kernel_size=config.kernel_size,
    n_classes=config.n_classes,
    dropout_rate=config.dropout_rate
)

checkpoint = torch.load('checkpoints/best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# Cr√©er le pruner
# Sahu et al. : 142x reduction avec <1% F1 loss
pruner = LTHECGPruner(
    model=model,
    target_reduction_factor=142,  # 10.5M ‚Üí 74K params
    initial_prune_rate=0.30,      # 30% initial
    alpha=1.1                     # Decay factor
)

# D√©finir fonction d'entra√Ænement
def train_function(model):
    # Votre logique d'entra√Ænement
    # Doit retourner validation F1-score
    trainer = Trainer(model, train_loader, val_loader, config, device)
    # ... train for few epochs ...
    return val_f1

# Lancer la compression
results = pruner.prune_iteratively(train_function, max_iterations=20)

# Sauvegarder mod√®le compress√©
pruner.save_pruned_model('checkpoints/lth_ecg_compressed.pth')

# R√©sultats attendus (Sahu et al. Table III)
# Initial: 10.5M params, 115 MB
# Final: 74K params (~0.8 MB), F1: 0.8360 (no degradation!)
```

## üìÅ Structure finale du projet

```
ecg_classification/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ physionet2017/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ REFERENCE.csv          # 8,528 labels
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ A00001.mat             # ECG recordings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ dataset.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ resnet1d.py                # 34-layer ResNet1D
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                 # F1, AUC, etc.
‚îÇ   ‚îî‚îÄ‚îÄ training.py                # Trainer class
‚îú‚îÄ‚îÄ checkpoints/
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pth             # ~115 MB
‚îÇ   ‚îî‚îÄ‚îÄ lth_ecg_compressed.pth     # ~0.8 MB
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ training_log.txt
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ roc_curves.png
‚îÇ   ‚îî‚îÄ‚îÄ evaluation_results.npz
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ train.py
‚îú‚îÄ‚îÄ evaluate.py
‚îú‚îÄ‚îÄ lth_ecg.py
‚îú‚îÄ‚îÄ test_setup.py
‚îú‚îÄ‚îÄ download_data.sh
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ QUICKSTART.md
```

## ‚öôÔ∏è Configuration personnalis√©e

Modifier `config.py` pour ajuster les hyperparam√®tres :

```python
class Config:
    # Training
    batch_size = 64            # R√©duire si GPU m√©moire limit√©e
    learning_rate = 5e-4       # Ajuster selon convergence
    max_epochs = 150           # Augmenter si besoin
    
    # Model
    base_filters = 32          # Hannun et al. default
    dropout_rate = 0.2         # Hannun et al. default
    
    # Data
    val_split = 0.1            # 10% validation (Hannun et al.)
    
    # Device
    device = 'cuda'            # ou 'cpu'
```

## üêõ D√©pannage rapide

### Erreur : CUDA out of memory
```python
# Dans config.py
batch_size = 32  # ou 16
```

### Erreur : Dataset not found
```bash
# V√©rifier le chemin
ls data/physionet2017/*.mat | head
cat data/physionet2017/REFERENCE.csv | head

# Re-t√©l√©charger si n√©cessaire
./download_data.sh
```

### Performance inf√©rieure aux benchmarks
1. Entra√Æner plus longtemps (100-150 √©poques)
2. V√©rifier l'√©quilibre des classes
3. Ajuster le learning rate
4. Utiliser data augmentation (rotation, scaling)

### Entra√Ænement trop lent sur CPU
```python
# Activer optimisations CPU
torch.set_num_threads(8)  # Ajuster selon votre CPU

# Ou louer GPU cloud :
# - Google Colab (gratuit, T4 GPU)
# - AWS EC2 (p3.2xlarge avec V100)
# - Lambda Labs (A100 GPU)
```

## üìà Prochaines √©tapes

1. **Validation** : F1-score ‚âà 0.836 ‚úì
2. **Compression** : Appliquer LTH-ECG (142x) ‚úì
3. **D√©ploiement** : Embarquer sur microcontr√¥leur (STM32)
4. **Extension** : √âtendre √† 12-lead ECG ou autres arythmies

## üéì R√©f√©rences rapides

- **Paper** : Hannun et al. (2019) Nature Medicine
- **Dataset** : https://physionet.org/content/challenge-2017/
- **Repo original** : https://github.com/awni/ecg
- **ResNet1D** : https://github.com/hsd1503/resnet1d
- **Compression** : Sahu et al. (2022) IEEE EMBC

---

**Temps total estim√©** : 4-8 heures (setup + training + evaluation)

**Questions ?** Consultez le README.md complet ou les articles r√©f√©renc√©s.